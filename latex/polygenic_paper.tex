\documentclass[a4paper,11pt]{article}
%Use article for short documents
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{latexsym,amsmath,amssymb}
%\usepackage{natbib}
\usepackage{graphicx}
\usepackage{times}
\usepackage{zi4}
\usepackage[a4paper,left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}

\title{Polygenic Markov Chain}
\author{Jesse Murray}

\begin{document}
\maketitle
\thispagestyle{empty}
\newpage
\pagenumbering{arabic}

\section{Introduction}
A simple Markov chain model is proposed that seeks to describe the movement of polygenic scores between familial generations. Some potentially useful properties are shown to result from this model. The model is compared with the data on the heights of 898 adult children and their parents, as collected by Francis Galton. 


\section{Model}

\subsection{Conceptual basis for polygenic analogy}

Polygenic traits are determined by many genes (hundreds or thousands), and their observed phenotypic scores generally normally distributed \cite{lange_article, lange_book}. Their normal distribution is theorized to result from the central limit theorem - as the phenotype of a polygenic trait (referred to as the score) results from the additive sum of many gene-effects, which are akin to independent random draws from an arbitrary distribution \cite{rieger}.


\subsection{Markov chain}
The proposed Markov chain exists in discrete time $\{0, 1, 2,...\}$, representing familial generations (parent, offspring, etc.); and continuous space $\mathbb{R}$, representing a continuous one-dimensional polygenic score. 

\begin{description}
\item [Convention] Let $Z$ indicate a standard normal $Z \sim \mathcal{N}(0, 1)$. All $Z$ are taken to be independent unless otherwise specified.
\end{description}

A complete description of the chain can be given in two parts: the initial condition and the one-step transition. 

\begin{enumerate}

\item The initial score is drawn from a normal distribution: $X_0 \sim \mathcal{N}(0, \sigma_0^2)$.

$$X_0 = \sigma_0 Z$$

\item The conditional one-step transition, i.e., the score of an offspring, given the score of its parent, is also drawn from a normal distribution: $X_{n+1}|X_n \sim \mathcal{N}(\tilde{\mu}_{n+1}, \tilde{\sigma}_{n+1}^2)$.

$$X_{n+1}|X_n = \tilde{\mu}_{n+1} + \tilde{\sigma}_n Z$$

\begin{enumerate}

\item An offspring's score is expected to be similar to that of its parent, although scaled by $r$ - the \emph{expectation regression coefficient}. Typically, $0 < r < 1$, such that there is - on average - regression towards the population mean.

$$\mathrm{E}(X_{n+1}|X_n) = \tilde{\mu}_{n+1} = rX_n$$

\item An offspring's score has a standard deviation that is similar to the standard deviation of the parent generation's population, although scaled by  $r_s$ - the \emph{standard deviation scaling coefficient}.

$$\sqrt{\mathrm{Var}(X_{n+1}|X_n)} =\tilde{\sigma}_{n+1} = r_s \sigma_n$$

\end{enumerate}
\end{enumerate}


\subsection{Further one-step properties}

The expectation regression coefficient also describes the covariance and correlation between parent and offspring scores. 

$$\mathrm{Cov}(X_{n+1}, X_n) = r \sigma_n^2$$

$$\mathrm{Corr}(X_{n+1}, X_n) = r \frac{\sigma_n}{\sigma_{n+1}}$$


\subsection{Arbitrary step-length properties}


$$\mathrm{E}(X_{n+j}|X_n) = \tilde{\mu}_{n+j} = r^jX_n$$

$$\sqrt{\mathrm{Var}(X_{n+j}|X_n)} = \tilde{\sigma}_{n+j} = \sigma_n \sqrt{(r^2+r_s^2)^j - r^{2j}}$$

For a stable population variance, the expression under the square root asymptotically approaches 1.







\subsection{The marginal random state}
It can be shown by induction and the theorem of the sum of independent normal random variables (rvs) that $X_n \sim \mathcal{N}(0, \sigma_n^2)$:

$$X_n = \sigma_nZ$$

Then, for $Z_a$, $Z_b$ iid standard normal rvs:

$$X_{n+1} = r\sigma_nZ_a + r_s\sigma_nZ_b$$



\subsection{Marginal variance}
It follows immediately that $\sigma_{n+1}^2$ has the following one-step relationship:

$$\sigma_{n+1}^2 = (r^2+r_s^2)  \sigma_n^2$$

By induction, $\sigma_n^2$ can also be stated in terms of the initial variance:

$$\sigma_n^2 = (r^2+r_s^2)^n  \sigma_{0}^2$$






\section{Stable population variance}
Let a stable population variance be defined as follows:

$$\sigma_{n+1}^2 = \sigma_n^2$$

The following are important properties that occur under stable population variance:

$$r^2+r_s^2 = 1$$

$$\mathrm{Corr}(X_{n+1}, X_n) = r$$

For an arbitrary state $i \ge 0$:

$$\sigma_i^2 = \sigma_{0}^2$$




\section{Transition kernel}

Let $A$ be a subset of the state space:

$$A \subseteq \mathbb{R}$$

\subsection{State to set transition}
Then the transition kernel $P(A, x_n)$ gives the one-step probability of reaching the set $A$ from the state $x_n$. 

$$P(A, x_n) = \int_{x_{n+1}\in A}^{} f(x_{n+1}|x_n)f(x_n) \, dx_{n+1}$$

Where $f(x_{n+1}|x_n)$ is the conditional probability density function (pdf) of $X_{n+1}|X_n \sim \mathcal{N}(\tilde{\mu}_{n+1}, \tilde{\sigma}_{n+1}^2)$, and $f(x_n)$ is the pdf of $X_n \sim \mathcal{N}(0, \sigma_n^2)$.

\subsection{Set to set transition}
A similar transition kernel $P(A, B)$ can be used to obtain the one-step probability of reaching the set $A$ from the set $B$. 

$$B \subseteq \mathbb{R}$$

$$P(A, B) = \int_{x_n\in B}^{} P(A, x_n) \, dx_n$$

\subsection{Probability attributable}
Define the probability that a current state $X_{n+1}$ in set $A$ resulted from or is 'attributable' to a previous state or parent score $X_n$ in set $B$.

$$\large P_{\alpha}(A, B) = \frac{P(A, B)}{P(A, \mathbb{R})}$$

By the law of total probability, $P(A, \mathbb{R})$ is the marginal probability that the state $X_{n+1}$ is in the space $A$, which is given by $P(A)$:

$$P(A) = \int_{x_{n+1}\in A} f(x_{n+1}) \, dx_{n+1}$$

Therefore:

$$P_{\alpha}(A, B) = \frac{P(A, B)}{P(A)}$$




\subsection{Probability destined}
Define the probability that a previous state $X_n$ in set $B$ will result in or is 'destined' for a current state or offspring score $X_{n+1}$ in set $A$. 

$$P_{\delta}(A, B) = \frac{P(A, B)}{P(\mathbb{R}, B)}$$

Because the integral over the entire support of a pdf equals 1, $P(\mathbb{R}, B)$ is the marginal probability that the state $X_n$ is in the space $B$, which is given by $P(B)$:

$$P(B) = \int_{x_{n+1}\in B} f(x_n) \, dx_n$$



Therefore:

$$P_{\delta}(A, B) = \frac{P(A, B)}{P(B)}$$


\section{Linear regression}

We have that:

$$\mathrm{E}(X_{n+1}|X_n) = rX_n, \qquad X_{n+1} = rX_n + \epsilon$$

This has the same form as the linear regression model where $b$ can be estimated by minimising the sum of the squared errors.

$$\mathrm{E}(Y|X) = bX, \qquad Y = bX + \epsilon, \qquad \mathrm{E}(\epsilon) = 0 $$

This means that $r$ can be estimated from existing one-step transition data through the least-squares method. 


\section{Reverse one-step transition}
The parent's phenotypic score is also a rv that is dependent on the offspring's phenotypic score. 

$$X_n = \frac{1}{r}X_{n+1} + \frac{r_s}{r}\sigma_nZ$$


$$X_n|X_{n+1} \sim \mathcal{N}(\frac{1}{r}X_{n+1}, \frac{r_s^2}{r^2}\sigma_n^2)$$


Where the variance can be rewritten in terms of the $n$th generation's variance:

$$\mathrm{Var}(X_n|X_{n+1}) = \frac{r_s^2}{r^2(r^2+r_s^2)} \sigma_{n+1}^2$$

\section{Eve's law}
It is possible to compute $\mathrm{Var(X_{n+1})}$ through Eve's law:

$$\mathrm{Var(X_{n+1})} = \mathrm{E}(\mathrm{Var}(X_n|X_{n+1})) + \mathrm{Var}(\mathrm{E}(X_{n+1}|X_n))$$

We have that:

$$X_{n+1} = rX_n + \tilde{\sigma}_{n+1} Z$$

$$\tilde{\sigma}_{n+1} = r_s \sigma_n$$

Therefore, each term in Eve's law is:

$$\mathrm{E}(\mathrm{Var}(X_{n+1}|X_n)) = \mathrm{E}(r_s^2 \sigma_n^2) = r_s^2 \sigma_n^2$$

$$\mathrm{Var}(\mathrm{E}(X_{n+1}|X_n)) = \mathrm{Var}(rX_n) = r^2\sigma_n^2$$

Combining these terms, we confirm the variance of $X_{n+1}$:

$$\sigma_{n+1}^2 = (r^2+r_s^2)  \sigma_n^2$$





\section{Use cases}
With the two parameters $r$ and $r_s$, we can perfectly describe the variance of the offspring's generation relative to that of the parent's generation through the following relation:

$$\frac{\sigma_{n+1}^2}{\sigma_n^2} = r^2+r_s^2$$

Simply knowing or having measured two of the three values: the ratio parent generation and offspring generation variance, the expectation regression coefficient ($r$), the standard deviation scaling coefficient ($r_s$); it is possible to obtain the third.

This can be useful, for example, to obtain the standard deviation of the offspring's polygenic score, after having measured the parent's polygenic score: $\tilde{\sigma}_{n+1} = r_s \sigma_n$.

Alternatively, after having only measured the $\frac{\sigma_{n+1}^2}{\sigma_n^2}$, which is 1 when there is stable population variance, and $r$, which can be obtained through ordinary least squares with the parent and offspring data or by the correlation coefficient between parent and offspring when there is stable population variance; the model can be constructed and applied.



\clearpage
\section*{Appendix}
\begin{verbatim}
Put your R code here.
\end{verbatim}

\bibliographystyle{apalike}
\bibliography{polygenic_bib}


\end{document}
